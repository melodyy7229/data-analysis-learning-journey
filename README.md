# Data Analysis Learning Journey
This repository documents my 8-week journey learning data analysis and AI.

## Week 1 - Programming Foundations for Data Analysis
- `Week1_Day4_Python_Basics.ipynb`: Python review covering variables, data types, and if/else logic.
- `Week1_Day5_Control_Flow.ipynb`: Python review covering if/else logic, for, and while.

## Week 2 - Data Foundations & Cleaning
- `Week2_Day1_Pandas_Intro.ipynb`: Completed the first two core modules— “Creating, Reading and Writing” and “Indexing, Selecting & Assigning”—in the Pandas course on Kaggle Learn. Practiced coding Jupyter Notebook to reinforce data structures and selection techniques.
- `Week2_Day2_Dictionary_Basics.ipynb`: Learned how to use Python dictionaries to store data using key-value pairs, and practiced basic operations like adding, updating, and looping through dictionary items.
- `Week2_Day3_Pandas_Basics.ipynb`: Found a simple CSV dataset. Loaded the dataset into a Pandas DataFrame using pd.read_csv() in Jupyter Notebook. Performed initial data exploration with .head(), .info(), and .describe(). Practiced selecting single and multiple columns, and filtering rows based on conditions to better understand basic data manipulation techniques.
- `Week2_Day4_Netflix_Cleaning.ipynb`: Downloaded the "Netflix Movies and TV Shows" dataset from Kaggle and loaded the netflix_titles.csv file into a new Jupyter Notebook. Performed basic data cleaning: checked for missing values, handled them preliminarily, and reviewed data types.

## Week 3 - SQL for Data Analysis
- `Week3_Day3_SQL_Practice.sql`: Used a sample database to practice basic SQL queries. Covered selecting all or specific columns, filtering with WHERE, sorting with ORDER BY, and combining both for more precise queries.
- `Week3_Day5_SQL_Finance_Practice.ipynb`: Built a simple local financial database using SQLite in Jupyter Notebook. Created tables for companies and financial reports, inserted sample data, and practiced SQL queries such as filtering by industry, calculating total revenue, and identifying top-performing companies by profit. Also created a reference page comparing SQL and Pandas syntax (SELECT vs. DataFrame selection, WHERE vs. filtering, GROUP BY vs. groupby).

## Week 4 - Data Visualization
- `Week4_Day1_Visualization_Intro.ipynb`: Started learning data visualization by completing the first module of Kaggle’s Data Visualization course. Explored key concepts and got hands-on with Seaborn for plotting. Also practiced creating basic line plots using Matplotlib in Jupyter notebook.
- `Week4_Day2_Create_Visuals.ipynb`: Practiced creating a variety of basic chart types—bar charts, horizontal bar charts, scatter plots, pie charts, and subplots. Focused on understanding when to use each type of chart and added Markdown notes to explain their ideal use cases.
- `Week4_Day4_Data_Visualization.ipynb`: Chose a real-world dataset (Google Play Store Apps), loaded and explored the dataset, performed basic cleaning, and built at three different types of visualizations (bar chart, scatter plot, and box plot). Added clear titles, axis labels, and legends for each chart, and used Markdown cells to explain insights and key takeaways from each visualization.

## Week 5 - Data Visualization & Financial Insights
- `Week5_Day1_Seaborn_Intro.ipynb`: Continued the Kaggle Learn Data Visualization course by completing the “Line Charts” and “Bar Charts and Heatmaps” modules. Practiced Seaborn basics like scatter plots with regression lines, categorical scatter plots, and box plots. Also explored advanced visualizations including heatmaps, pair plots, violin plots, joint plots, and facet grids. 
- `Week5_Day4_Taiwan_ETF_Analysis.ipynb`: Collected Taiwan ETF data using the yfinance library and performed a visual analysis in this notebook. Calculated key performance metrics such as annualized returns, volatility, and Sharpe ratio. Created various visualizations to explore performance, risk-return relationships, ETF correlations, and potential seasonal patterns. Added Markdown notes to explain key findings and highlight the best-performing ETFs.

## Week 6 - Data Refinement & SQL-Style Analysis
- `Week6_Day1_Cleaning_And_Visualization.ipynb`: Selected one of the small analysis projects from previous weeks (netflix_titles.csv). Focused on cleaning and visualizing the data to produce clearer insights and more polished charts.
- `Week6_Day5_SQL_Python_Integration.ipynb`: Chose a Kaggle dataset— Ecommerce Orders Data Set. Created a new notebook to define analysis goals, prepare the data, and perform groupby and aggregation operations in Pandas (similar to SQL GROUP BY). Visualized the results using Matplotlib and Seaborn.

## Week 7 - R Programming & Bellabeat Case Study
- `Bellabeat Case study`: Learned R basics through the Google Data Analytics Course including data types, vectors, data frames, and essential functions. Practiced data cleaning and manipulation using `tidyverse` packages (`dplyr`, `ggplot2`). Completed the Bellabeat capstone case study from the Google Data Analytics Certificate. Analyzed smart device usage data to identify trends in activity, sleep, and wellness habits. Cleaned and transformed datasets, created visualizations with `ggplot2`, and summarized insights. Added Markdown documentation to highlight recommendations for Bellabeat’s marketing strategy.
- `Google Data Analytics Certificate.pdf`: Completed the Google Data Analytics Professional Certificate, covering data cleaning, visualization, SQL, R, and applied analytics projects.
